# Nadia

Nadia is a data analyst who specialises in identifying and mitigating biases in machine learning algorithms and AI-generated recommendations.


## Goal

Nadia wants to carry out research regarding the issues of bias in algorithms trained to identify harmful content.


## Scenario

Nadia is interested in investigating bias in algorithms trained to identify harmful content. These algorithms, while intended to protect online spaces, can inadvertently perpetuate or amplify social biases. For instance, algorithmsâ€™ outcomes may systematically and unfairly flag or overlook certain groups or types of content. This could have social implications, where the results may disproportionately affect people based on their race, gender, sexual orientation, among others, sensitive attributes. 
She would like to explore definitions of online harms from the perspective of technology and regulations, and the impact of such harms in economic and social terms, while uncovering how women and girls experience online platforms and the impact of algorithmic bias on their online safety.


## Competency Questions (CQs)

- What language is used to describe online harms (from a legal, practitioner, tech/software perspective)?
- How do law and technology respond to online harms? For instance, regulations (local or international), tech/software good practices or recommendations
- What is the economic and social impact of online harm against women and girls?
- What kind of harmful content, targeting women and girls, is less likely to be detected by AI systems or social platforms?
